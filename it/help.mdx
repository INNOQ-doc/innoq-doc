---
title: PerchÃ© il mio chatbot non risponde correttamente alle domande?
description: Scopri perchÃ© i chatbot basati su LLM a volte rispondono in modo errato e come funziona la Retrieval Augmented Generation (RAG).
---

Quando gli scienziati di Google hanno presentato per la prima volta il concetto di **Transformer**[](https://arxiv.org/pdf/1706.03762.pdf), ha ricevuto molta attenzione nella comunitÃ  NLP.  
Ha costituito la base per nuove reti neurali dedicate al processamento e alla comprensione del linguaggio naturale.

Poco dopo, OpenAI ha reso popolari i **modelli GPT** e, con ChatGPT, ha inaugurato lâ€™era dei **Large Language Models (LLM)**.  
Le prestazioni conversazionali di questi modelli hanno fatto credere a molti che lâ€™IA fosse sul punto di raggiungere lâ€™intelligenza umana.

Tuttavia, nonostante il loro comportamento â€œumanoâ€, gli LLM **non** vedono, interpretano nÃ© comprendono il mondo come gli esseri umani.  
Non sono macchine logiche di ragionamento, ma piuttosto **simulatori conversazionali probabilistici**.  
Il loro comportamento si basa sul **riconoscimento di pattern** e sulle **correlazioni semantiche**, non sulla logica o sulla comprensione.

INNOCHAT Ã¨ alimentato dai LLM di OpenAI e utilizza la **Retrieval Augmented Generation (RAG)** per adattare le risposte in base ai dati caricati dallâ€™utente.

## Che cosâ€™Ã¨ la Retrieval Augmented Generation (RAG)?

Gli LLM vengono addestrati su enormi quantitÃ  di testo.  
Riconoscono pattern e generano nuovo testo basandosi sulla probabilitÃ  che determinati Â«tokenÂ» (parole o parti di parole) si susseguano.

Per questo motivo OpenAI chiama molti dei suoi endpoint **Chat Completions** â€” il modello Â«completaÂ» il prompt.

<Note>
  Una spiegazione dettagliata sui token Ã¨ disponibile nella documentazione ufficiale OpenAI:  
  https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them
</Note>

Ma: **i pattern non significano veritÃ .**  
Gli LLM possono molto facilmente **allucinare** quando non dispongono di dati rilevanti.

La RAG cerca di risolvere questo problema aggiungendo al prompt un contesto supplementare che influenza le probabilitÃ .

### Esempio

Prompt senza contesto:
```
Cosâ€™Ã¨ INNOCHAT?
```
Questa Ã¨ una query che si basa interamente sui pattern semantici presenti nei dati di addestramento di base del modello. Non câ€™Ã¨ alcuna garanzia che la risposta sia corretta o affidabile.  
Ma cosa succede se il prompt diventa:

```
Rispondi alla seguente domanda utilizzando il contesto qui sotto:
INNOCHAT Ã¨ un potente framework No-Code / Low-Code che ti permette di creare chatbot multi-agente con capacitÃ  di function calling, utilizzando i tuoi dati. Ãˆ progettato per essere user-friendly e versatile, offrendo numerose opzioni di personalizzazione e integrazione con le piattaforme piÃ¹ comuni.
Cosâ€™Ã¨ INNOCHAT?
```


Ora il modello viene fortemente indirizzato verso le informazioni fornite.  
Il contesto influenza la generazione dei token e porta a una risposta molto piÃ¹ precisa.

Questo Ã¨ **RAG**: arricchire il prompt con fonti di conoscenza rilevanti, senza modificare il modello stesso.

### PerchÃ© non inseriamo semplicemente *tutti* i dati in una volta?

PerchÃ© esistono **limiti di token**.

Un modello OpenAI come gpt-3.5-16k puÃ² gestire circa **10.000 parole** di contesto.  
La tua base di conoscenza spesso comprende centinaia di pagine o migliaia di documenti â€” molto piÃ¹ di quanto possa entrare in una singola finestra LLM.

Ecco perchÃ©:

1. I documenti vengono suddivisi in **chunk**  
2. Ogni chunk viene Â«incorporatoÂ» (embedding)  
3. Gli embedding vengono salvati in un **database vettoriale**  
4. A ogni richiesta utente vengono cercati i **chunk piÃ¹ rilevanti**  
5. Questi vengono inseriti nel prompt  
6. Lâ€™LLM risponde sulla base di questo prompt contestualizzato  

Un embedding Ã¨ una **rappresentazione matematica del significato** di un frammento di testo.  
Frasi simili si trovano Â«piÃ¹ vicineÂ» nello spazio vettoriale.

Una buona introduzione agli embedding:  
https://stackoverflow.blog/2023/11/09/an-intuitive-introduction-to-text-embeddings/

### Esempio: query Â«What is innoChat?Â»

Il chunk piÃ¹ rilevante Ã¨:


```
Che cosâ€™Ã¨ INNOCHAT?
```
Questa Ã¨ una richiesta che si basa interamente sui pattern semantici presenti nei dati di training di base del modello per generare una risposta. Non vi Ã¨ alcuna garanzia che la risposta sia corretta o affidabile. Ma cosa succede se il prompt viene modificato come segue:


```
innoChat Ã¨ un potente framework No-Code / Low-Code che ti permette di creare chatbot multi-agente con capacitÃ  di function calling, utilizzando i tuoi dati. Ãˆ progettato per essere user-friendly e versatile, offrendo numerose opzioni di personalizzazione e integrazione con le piattaforme piÃ¹ comuni.
```


Con questo contesto, lâ€™LLM puÃ² generare una risposta corretta.

AWS offre una buona panoramica visiva del processo RAG:

<Frame caption="https://docs.aws.amazon.com/sagemaker/latest/dg/jumpstart-foundation-models-customize-rag.html">
  <img src="/images/help-1.png" />
</Frame>

## Quali tipi di domande funzionano bene?

| Tipo di query              | Descrizione                                                        | Esempio                                                      |
|----------------------------|--------------------------------------------------------------------|--------------------------------------------------------------|
| Ricerca di informazioni    | Ricerca di informazioni concrete nei documenti                     | Â«Qual Ã¨ la politica ferie di Paladin Max, Inc.?Â»             |
| Riassunti tematici         | Riassunto di un ambito tematico                                    | Â«Riassumi gli ultimi sviluppi nellâ€™IA generativaÂ»            |

## Quali tipi di domande funzionano male?

| Tipo di query                      | Descrizione                                                                | Esempio                                                                     |
|------------------------------------|----------------------------------------------------------------------------|-----------------------------------------------------------------------------|
| Confronto tra documenti            | Confronto senza criteri chiari                                             | Â«Trova le incoerenze in tutti gli argomenti dei miei documenti.Â»           |
| Conteggio o calcoli matematici     | Analisi quantitativa basata sui dati di addestramento                      | Â«Quante volte compare John in tutti i contratti?Â»                           |
| Istruzioni di livello meta         | Riferimento alla struttura / numerazione delle pagine                      | Â«Riassumi la sezione 3 (pagine 33â€“37) di questo report.Â»                    |
| Query statistiche sullâ€™intero set  | Domande statistiche su piÃ¹ documenti                                       | Â«Quanti documenti menzionano lâ€™argomento X e elencali in una tabella.Â»      |
| Generazione di testo lungo         | Testi molto lunghi basati sui documenti forniti                            | Â«Scrivi una revisione della letteratura di 5000 parole.Â»                    |

Se il tuo caso dâ€™uso richiede questi compiti piÃ¹ complessi, puoi utilizzare:

- unâ€™architettura multi-agente  
- il function calling  

â€” ciÃ² richiede perÃ² una configurazione avanzata.

---

Ãˆ possibile migliorare le prestazioni del tuo chatbot ottimizzando i dati di addestramento.  
Leggi a riguardo:

ğŸ‘‰ **[Best practices per la preparazione dei dati di addestramento](/best-practices)**


