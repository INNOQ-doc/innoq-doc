---
title: Pourquoi mon chatbot ne rÃ©pond-il pas correctement aux questions ?
description: DÃ©couvrez pourquoi les chatbots basÃ©s sur LLM rÃ©pondent parfois de maniÃ¨re incorrecte et comment fonctionne la Retrieval Augmented Generation (RAG).
---

Lorsque les chercheurs de Google ont prÃ©sentÃ© pour la premiÃ¨re fois le concept de **Transformer**[](https://arxiv.org/pdf/1706.03762.pdf), il a suscitÃ© beaucoup dâ€™attention dans la communautÃ© NLP.  
Il a constituÃ© la base de nouveaux rÃ©seaux neuronaux pour le traitement et la comprÃ©hension du langage naturel.

Peu aprÃ¨s, OpenAI a popularisÃ© les **modÃ¨les GPT** et, avec ChatGPT, a lancÃ© lâ€™Ã¨re des **Large Language Models (LLM)**.  
Les performances conversationnelles de ces modÃ¨les ont conduit beaucoup de gens Ã  croire que lâ€™IA Ã©tait sur le point dâ€™atteindre lâ€™intelligence humaine.

Pourtant, malgrÃ© leur comportement Â« humain Â», les LLM ne voient, nâ€™interprÃ¨tent et ne comprennent **pas** le monde comme les humains.  
Ce ne sont pas des machines Ã  raisonner logiquement, mais plutÃ´t des **simulateurs conversationnels probabilistes**.  
Leur comportement repose sur la **reconnaissance de motifs** et les **corrÃ©lations sÃ©mantiques**, et non sur la logique ou la comprÃ©hension.

INNOCHAT est propulsÃ© par les LLM dâ€™OpenAI et utilise la **Retrieval Augmented Generation (RAG)** pour adapter les rÃ©ponses en fonction de vos donnÃ©es tÃ©lÃ©chargÃ©es.

## Quâ€™est-ce que la Retrieval Augmented Generation (RAG) ?

Les LLM sont entraÃ®nÃ©s sur dâ€™Ã©normes quantitÃ©s de texte.  
Ils reconnaissent des motifs et gÃ©nÃ¨rent de nouveaux textes en se basant sur la probabilitÃ© que certains Â« tokens Â» (mots ou parties de mots) se suivent.

Câ€™est pourquoi OpenAI nomme beaucoup de ses endpoints **Chat Completions** â€” le modÃ¨le Â« complÃ¨te Â» le prompt.

<Note>
  Une explication dÃ©taillÃ©e des tokens est disponible dans la documentation officielle OpenAI :  
  https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them
</Note>

Mais : **les motifs ne signifient pas la vÃ©ritÃ©.**  
Les LLM peuvent trÃ¨s facilement **halluciner** lorsquâ€™aucune donnÃ©e pertinente nâ€™est disponible.

La RAG tente de rÃ©soudre ce problÃ¨me en ajoutant au prompt un contexte supplÃ©mentaire qui influence les probabilitÃ©s.

### Exemple

Prompt sans contexte :
```
Was ist INNOCHAT?
```
Cette requÃªte repose entiÃ¨rement sur les motifs sÃ©mantiques prÃ©sents dans les donnÃ©es dâ€™entraÃ®nement de base du modÃ¨le. Il nâ€™y a aucune garantie que la rÃ©ponse soit correcte ou fiable.  
Mais que se passe-t-il si le prompt devient :

```
RÃ©pondez Ã  la question suivante en utilisant le contexte ci-dessous :
INNOCHAT est un puissant framework No-Code / Low-Code qui vous permet de crÃ©er des chatbots multi-agents dotÃ©s de capacitÃ©s dâ€™appel de fonctions, en utilisant vos propres donnÃ©es. Il est conÃ§u pour Ãªtre convivial et polyvalent, avec de nombreuses options de personnalisation et une intÃ©gration avec les plateformes courantes.
Quâ€™est-ce quâ€™INNOCHAT ?
```


Le modÃ¨le est alors fortement orientÃ© vers les informations fournies.  
Le contexte influence la gÃ©nÃ©ration des tokens et conduit Ã  une rÃ©ponse beaucoup plus prÃ©cise.

Câ€™est cela la **RAG** : enrichir le prompt avec des sources de connaissance pertinentes, sans modifier le modÃ¨le lui-mÃªme.

### Pourquoi ne pas simplement envoyer *toutes* les donnÃ©es en mÃªme temps ?

Parce quâ€™il existe des **limites de tokens**.

Un modÃ¨le OpenAI comme gpt-3.5-16k peut gÃ©rer environ **10 000 mots** de contexte.  
Votre base de connaissances comporte souvent des centaines de pages ou des milliers de documents â€” bien plus que ce qui rentre dans une seule fenÃªtre LLM.

Câ€™est pourquoi :

1. Les documents sont dÃ©coupÃ©s en **chunks**  
2. Chaque chunk est Â« encodÃ© Â» (embedding)  
3. Les embeddings sont stockÃ©s dans une **base de donnÃ©es vectorielle**  
4. Ã€ chaque requÃªte utilisateur, on recherche les **chunks les plus pertinents**  
5. Ces chunks sont insÃ©rÃ©s dans le prompt  
6. Le LLM rÃ©pond sur la base de ce prompt contextualisÃ©  

Un embedding est une **reprÃ©sentation mathÃ©matique du sens** dâ€™un extrait de texte.  
Des phrases similaires se trouvent Â« plus proches Â» dans lâ€™espace vectoriel.

Une bonne introduction aux embeddings :  
https://stackoverflow.blog/2023/11/09/an-intuitive-introduction-to-text-embeddings/

### Exemple : requÃªte Â« What is innoChat ? Â»

Le chunk le plus pertinent est :


```
Quâ€™est-ce quâ€™INNOCHAT ?
```

La partie la plus pertinente, probablement extraite de notre base de donnÃ©es vectorielle, est :

```
innoChat est un puissant framework No-Code / Low-Code qui vous permet de crÃ©er des chatbots multi-agents dotÃ©s de capacitÃ©s dâ€™appel de fonctions, en utilisant vos propres donnÃ©es. Il est conÃ§u pour Ãªtre convivial et polyvalent, avec de nombreuses options de personnalisation et une intÃ©gration avec les plateformes courantes.
```


Avec ce contexte, le LLM peut gÃ©nÃ©rer une rÃ©ponse correcte.

AWS propose une bonne vue dâ€™ensemble visuelle du processus RAG :

<Frame caption="https://docs.aws.amazon.com/sagemaker/latest/dg/jumpstart-foundation-models-customize-rag.html">
  <img src="/images/help-1.png" />
</Frame>

## Quels types de questions fonctionnent bien ?

| Type de requÃªte            | Description                                                        | Exemple                                                      |
|----------------------------|--------------------------------------------------------------------|--------------------------------------------------------------|
| Recherche dâ€™information    | Recherche dâ€™informations concrÃ¨tes dans les documents              | Â« Quelle est la politique de congÃ©s payÃ©s de Paladin Max, Inc. ? Â» |
| RÃ©sumÃ©s thÃ©matiques        | RÃ©sumÃ© dâ€™un domaine thÃ©matique                                     | Â« RÃ©sumez les derniers dÃ©veloppements en IA gÃ©nÃ©rative Â»     |

## Quels types de questions fonctionnent mal ?

| Type de requÃªte                      | Description                                                                | Exemple                                                                 |
|--------------------------------------|----------------------------------------------------------------------------|-------------------------------------------------------------------------|
| Comparaison de documents             | Comparaison sans critÃ¨res clairs                                           | Â« Trouve les incohÃ©rences dans tous les arguments de mes documents. Â»   |
| Comptage ou calculs mathÃ©matiques    | Analyse quantitative basÃ©e sur les donnÃ©es dâ€™entraÃ®nement                  | Â« Combien de fois John est-il mentionnÃ© dans tous les contrats ? Â»      |
| Instructions de niveau mÃ©ta         | RÃ©fÃ©rence Ã  la structure / numÃ©rotation des pages                          | Â« RÃ©sumez la section 3 (pages 33â€“37) de ce rapport. Â»                   |
| RequÃªtes statistiques sur lâ€™ensemble | Questions statistiques sur plusieurs documents                             | Â« Combien de documents mentionnent le sujet X et liste-les dans un tableau. Â» |
| GÃ©nÃ©ration de texte long             | Textes trÃ¨s longs basÃ©s sur les documents fournis                          | Â« RÃ©dige une revue de littÃ©rature de 5000 mots. Â»                       |

Si votre cas dâ€™usage nÃ©cessite ces tÃ¢ches plus complexes, vous pouvez utiliser :

- une architecture multi-agents  
- le function calling  

â€” cela nÃ©cessite toutefois une configuration avancÃ©e.

---

Il est possible dâ€™amÃ©liorer les performances de votre chatbot en optimisant vos donnÃ©es dâ€™entraÃ®nement.  
Consultez Ã  ce sujet :

ğŸ‘‰ **[Bonnes pratiques pour la prÃ©paration des donnÃ©es dâ€™entraÃ®nement](/best-practices)**


