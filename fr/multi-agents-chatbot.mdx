---
title: Chatbot multi-agents
description: Découvrez comment INNOCHAT utilise une architecture multi-agents pour des automatisations performantes.
---

INNOCHAT est le premier et le plus puissant framework No-Code d’IA conversationnelle à implémenter une architecture multi-agents.  
Plusieurs agents IA travaillent ensemble dans une orchestration coordonnée afin de permettre des automatisations de workflow avancées.

<Frame>
  <img src="/images/multi-agents-chatbot-7.png" />
</Frame>

Ce guide a pour objectif de vous aider à comprendre comment nos agents collaborent, tout en vous transmettant les meilleures pratiques pour concevoir un chatbot multi-agents.

Tous les agents possèdent deux états :

- **Actif :** L’agent est « Connected ». Il est en ligne et actif.  
- **Inactif :** L’agent est « Disabled ». Il n’exécute aucune action.

À tout moment, **un seul agent** interagit directement avec l’utilisateur.  
Notre **superviseur IA** travaille en arrière-plan en temps réel et décide quel agent doit traiter la demande de l’utilisateur.

<Note>
  Les agents sont totalement isolés les uns des autres.  
  Cela signifie :
  - Vous ne pouvez pas donner d’instructions à l’agent B depuis l’agent A.  
  - Vous ne pouvez pas demander au superviseur IA de « passer le relais ».  
  - Le superviseur IA ne peut pas être instruit par langage naturel.
</Note>

Le superviseur IA répartit les requêtes des utilisateurs entre les agents en fonction de leur **description d’agent**.  
Si vous n’avez qu’un seul agent, la description est moins importante.  
En revanche, avec plusieurs agents, elle doit être **aussi claire et précise que possible**.

- **Agent Description** – Quelles tâches l’agent doit-il accomplir ?  
- **Agent Prompt** – Comment l’agent doit-il exécuter ces tâches ?

<Frame>
  <img src="/images/multi-agents-chatbot-5.png" />
</Frame>

<Note>
  La description de l’agent est différente du prompt.  
  La description explique au superviseur IA, à un niveau élevé, quels types de requêtes l’agent doit traiter.  
  Le prompt contient, quant à lui, des instructions détaillées sur le comportement de l’agent.
</Note>

De bonnes descriptions d’agents répondent à la question :  
**« Quels types de requêtes l’agent doit-il traiter ? »**

Elles doivent inclure toutes les **intentions utilisateur** pertinentes que l’agent doit couvrir.

Les descriptions d’agents ne doivent **pas** expliquer *comment* l’agent accomplit ses tâches — cela relève du prompt.

Voici quelques exemples de bonnes descriptions d’agents :

<AccordionGroup>
  <Accordion title="INNOCHAT Support">
    Incarnate the role of "INNOCHAT Expert," a specialized guide for INNOCHAT. Your main objective is to assist users with answering INNOCHAT-related questions related to:
    - Use cases
    - Features and capabilities
    - Data security
    - Pricing
    - AI Agents and multi-Agent architecture
    - User identity verification
    - Chunk curation
    - Function calling
    - Partnership program
    - Custom domains
    - Tokens

    All intents handled by this Agent should be related to INNOCHAT.
  </Accordion>

{" "}

  <Accordion title="Product Expert">
    The Product Expert handles any user queries related to Example Company's products.  
    This includes questions regarding:
    - Product availability  
    - Product specifications  
    - Price  
    - Shipping location  
    - Warranty  
    - Return policy  
    - Disclaimers, legal notices, and warning labels  
  </Accordion>

{" "}

  <Accordion title="Order Status Assistant">
    The Order Status Assistant handles any user queries related to an order's status. This includes:
    - Product package tracking  
    - Current package location  
    - Estimated delivery time  
    - Late delivery compensation  
  </Accordion>
</AccordionGroup>

Qu’est-ce qui caractérise une bonne conception de chatbot multi-agents ?  
Comment s’assurer que toutes les intentions utilisateur sont traitées par le bon agent ?

En principe, une architecture multi-agents est idéale pour faire collaborer des agents IA spécialisés en équipe.  
Chaque agent peut :

- accéder à des données d’entraînement différentes,  
- être alimenté par un LLM différent,  
- disposer de son propre prompt,  
- avoir ses propres outils (Functions).

C’est bien plus efficace que de tout regrouper dans un seul agent.

Du point de vue de l’utilisateur, la présence de plusieurs agents n’est pas perceptible — l’orchestration est totalement transparente en arrière-plan.  
Avec une configuration correcte, le chat donne l’impression d’une conversation humaine.  
Un chatbot multi-agents peut être nettement plus performant que les systèmes à agent unique comme ChatGPT.

Notre routage du superviseur IA utilise un algorithme qui équilibre **latence et précision**.  
Il ne sera pas toujours correct à 100 %, mais avec une bonne conception, vous pouvez vous en approcher de très près.

## Débogage du chatbot

Si le chatbot ne réagit pas comme prévu, deux causes sont possibles :

1. Le mauvais agent a été sélectionné pour traiter la requête.  
2. Le bon agent a été sélectionné, mais il n’est pas configuré de manière optimale.

Pour vérifier si le bon agent a été sélectionné, allez dans **Inbox** et activez le mode débogage :

<Frame>
  <img src="/images/multi-agents-chatbot-6.png" />
</Frame>

Sous **Active Agent**, vous pouvez voir quel agent a généré la réponse.  
Cette information n’est affichée que lorsque plusieurs agents sont connectés.

Si le mauvais agent a répondu, modifiez sa configuration — nom, description ou prompt.

Si le bon agent a répondu mais que la réponse ne convient pas, le problème vient de l’agent lui-même.  
Le moyen le plus simple d’améliorer cela consiste à corriger directement la réponse :

<Frame>
  <img src="/images/multi-agents-chatbot-4.png" />
</Frame>

Cela garantit que le chatbot répondra à l’avenir à la même question en se basant sur votre correction — à condition que le même agent soit sélectionné.

Pour rendre l’agent plus robuste de manière générale, vous pouvez :

- organiser et affiner les données d’entraînement,  
- utiliser un LLM plus performant,  
- rendre le prompt de base plus précis.

Informations complémentaires :

- Bonnes pratiques pour les données d’entraînement : **[best practices for preparing training data](/best-practices)**  
- Affiner les intentions des agents : **[Fine-Tuning Agent Intents](fine-tuning-agent-intents)**  
